--- chromium-87.0.4280.67.orig/third_party/skia/BUILD.gn
+++ chromium-87.0.4280.67/third_party/skia/BUILD.gn
@@ -132,7 +132,8 @@
 is_x86 = current_cpu == "x64" || current_cpu == "x86"
 
 opts("none") {
-  enabled = !is_x86 && current_cpu != "arm" && current_cpu != "arm64"
+  enabled = !is_x86 && current_cpu != "arm" && current_cpu != "arm64" &&
+      current_cpu != "ppc64"
   sources = skia_opts.none_sources
   cflags = []
 }
@@ -221,6 +222,11 @@
   }
 }
 
+opts("vsx") {
+  enabled = current_cpu == "ppc64"
+  sources = skia_opts.vsx_sources
+}
+
 opts("skx") {
   enabled = is_x86
   sources = skia_opts.skx_sources
@@ -1170,6 +1176,7 @@
     ":sse41",
     ":sse42",
     ":ssse3",
+    ":vsx",
     ":webp_decode",
     ":webp_encode",
     ":wuffs",
@@ -1341,6 +1348,7 @@
     ":sse41",
     ":sse42",
     ":ssse3",
+    ":vsx",
   ]
 
   # This file (and all GN files in Skia) are designed to work with an
--- chromium-87.0.4280.67.orig/third_party/skia/gn/BUILD.gn
+++ chromium-87.0.4280.67/third_party/skia/gn/BUILD.gn
@@ -155,6 +155,8 @@
       "-mfpmath=sse",
     ]
     ldflags += [ "-m32" ]
+  } else if (current_cpu == "ppc64") {
+    cflags += [ "-mcpu=power9", "-mtune=power9" ]
   }
 
   if (malloc != "" && !is_win) {
--- chromium-87.0.4280.67.orig/third_party/skia/gn/shared_sources.gni
+++ chromium-87.0.4280.67/third_party/skia/gn/shared_sources.gni
@@ -26,5 +26,6 @@
   sse42_sources = sse42
   avx_sources = avx
   hsw_sources = hsw
+  vsx_sources = ssse3
   skx_sources = skx
 }
--- chromium-87.0.4280.67.orig/third_party/skia/include/core/SkTypes.h
+++ chromium-87.0.4280.67/third_party/skia/include/core/SkTypes.h
@@ -169,6 +169,42 @@
     #define SK_ARM_HAS_CRC32
 #endif
 
+//////////////////////////////////////////////////////////////////////
+// PPC defines
+
+#if defined(__powerpc64__) || defined(__PPC64__)
+    #define SK_CPU_PPC64
+#endif
+
+// Newer versions of clang and gcc for ppc64 ship with wrappers that translate
+// Intel vector intrinsics into PPC VSX instrinsics, so we can pretend to have
+// to be Intel. Currently, full API support for SSSE3 on POWER8 and later
+// processors.
+#if defined(__POWER8_VECTOR__) && defined(__has_include) && \
+  !defined(SK_CPU_SSE_LEVEL)
+
+    // Clang ships both Intel and PPC headers in its PPC version, storing the
+    // PPC compatibility in a subdirectory that the compiler will include before
+    // its standard library include directory.
+    #if (__has_include(<tmmintrin.h>) && !defined(__clang__)) || \
+         __has_include(<ppc_wrappers/tmmintrin.h>)
+        #define SK_CPU_SSE_LEVEL    SK_CPU_SSE_LEVEL_SSSE3
+    #elif (__has_include(<emmintrin.h>) && !defined(__clang__)) || \
+           __has_include(<ppc_wrappers/emmintrin.h>)
+        #define SK_CPU_SSE_LEVEL    SK_CPU_SSE_LEVEL_SSE2
+    #endif
+
+    #ifdef SK_CPU_SSE_LEVEL
+        #define SK_PPC64_HAS_SSE_COMPAT
+        #ifndef NO_WARN_X86_INTRINSICS
+            #define NO_WARN_X86_INTRINSICS
+        #endif
+        #if defined(__clang__)
+            #define SK_PPC64_CLANG_MFPPR_BUG
+        #endif
+    #endif
+#endif
+
 
 // DLL/.so exports.
 #if !defined(SKIA_IMPLEMENTATION)
--- chromium-87.0.4280.67.orig/third_party/skia/include/private/SkVx.h
+++ chromium-87.0.4280.67/third_party/skia/include/private/SkVx.h
@@ -30,6 +30,15 @@
     #include <immintrin.h>
 #elif defined(__ARM_NEON)
     #include <arm_neon.h>
+#elif defined(__POWER8_VECTOR__) && defined(__has_include)
+    #if (__has_include(<emmintrin.h>) && !defined(__clang__)) || \
+         __has_include(<ppc_wrappers/emmintrin.h>)
+        #define HAS_PPC64_SSE_COMPAT
+        #ifndef NO_WARN_X86_INTRINSICS
+            #define NO_WARN_X86_INTRINSICS
+        #endif
+        #include <emmintrin.h>
+    #endif
 #elif defined(__wasm_simd128__)
     #include <wasm_simd128.h>
 #endif
@@ -552,7 +561,7 @@
         return unchecked_bit_pun<Vec<N,int>>(_mm256_cvtps_epi32(unchecked_bit_pun<__m256>(x)));
     }
 #endif
-#if defined(__SSE__)
+#if defined(__SSE__) || defined(HAS_PPC64_SSE_COMPAT)
     if /*constexpr*/ (N == 4) {
         return unchecked_bit_pun<Vec<N,int>>(_mm_cvtps_epi32(unchecked_bit_pun<__m128>(x)));
     }
@@ -688,7 +697,7 @@
         }
     #endif
 
-    #if defined(__SSE__)
+    #if defined(__SSE__) || defined(HAS_PPC64_SSE_COMPAT)
         SI Vec<4,float> rsqrt(const Vec<4,float>& x) {
             return bit_pun<Vec<4,float>>(_mm_rsqrt_ps(bit_pun<__m128>(x)));
         }
@@ -733,5 +742,6 @@
 #undef SINT
 #undef SIT
 #undef SI
+#undef HAS_PPC64_SSE_COMPAT

 #endif//SKVX_DEFINED
--- chromium-87.0.4280.67.orig/third_party/skia/src/core/SkSpinlock.cpp
+++ chromium-87.0.4280.67/third_party/skia/src/core/SkSpinlock.cpp
@@ -31,7 +31,8 @@
 #endif
 
 // Renamed from "pause" to avoid conflict with function defined in unistd.h
-#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
+#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2 && \
+    !defined(SK_PPC64_CLANG_MFPPR_BUG)
     #include <emmintrin.h>
     static void do_pause() { _mm_pause(); }
 #else
--- chromium-87.0.4280.67.orig/third_party/skia/src/opts/SkBitmapProcState_opts.h
+++ chromium-87.0.4280.67/third_party/skia/src/opts/SkBitmapProcState_opts.h
@@ -21,7 +21,9 @@
 // The rest are scattershot at the moment but I want to get them
 // all migrated to be normal code inside SkBitmapProcState.cpp.
 
-#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
+#if defined(SK_PPC64_HAS_SSE_COMPAT)
+    #include <emmintrin.h>
+#elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
     #include <immintrin.h>
 #elif defined(SK_ARM_HAS_NEON)
     #include <arm_neon.h>
--- chromium-87.0.4280.67.orig/third_party/skia/src/opts/SkBlitRow_opts.h
+++ chromium-87.0.4280.67/third_party/skia/src/opts/SkBlitRow_opts.h
@@ -100,7 +100,7 @@
 #endif
 
 #if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSE2
-    #include <immintrin.h>
+    #include <emmintrin.h>
 
     static inline __m128i SkPMSrcOver_SSE2(const __m128i& src, const __m128i& dst) {
         __m128i scale = _mm_sub_epi32(_mm_set1_epi32(256),
--- chromium-87.0.4280.67.orig/third_party/skia/src/opts/SkRasterPipeline_opts.h
+++ chromium-87.0.4280.67/third_party/skia/src/opts/SkRasterPipeline_opts.h
@@ -68,6 +68,8 @@
     #define JUMPER_IS_SCALAR
 #elif defined(SK_ARM_HAS_NEON)
     #define JUMPER_IS_NEON
+#elif defined(SK_PPC64_HAS_SSE_COMPAT)
+    #define JUMPER_IS_VSX
 #elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SKX
     #define JUMPER_IS_SKX
 #elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_AVX2
@@ -100,6 +102,8 @@
     #include <math.h>
 #elif defined(JUMPER_IS_NEON)
     #include <arm_neon.h>
+#elif defined(JUMPER_IS_VSX)
+    #include <emmintrin.h>
 #else
     #include <immintrin.h>
 #endif
@@ -671,7 +675,8 @@
         }
     }
 
-#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41)
+#elif defined(JUMPER_IS_SSE2) || defined(JUMPER_IS_SSE41) || \
+  defined(JUMPER_IS_VSX)
     template <typename T> using V = T __attribute__((ext_vector_type(4)));
     using F   = V<float   >;
     using I32 = V< int32_t>;
@@ -712,6 +717,8 @@
     SI F floor_(F v) {
     #if defined(JUMPER_IS_SSE41)
         return _mm_floor_ps(v);
+    #elif defined(JUMPER_IS_VSX)
+        return vec_floor(v);
     #else
         F roundtrip = _mm_cvtepi32_ps(_mm_cvttps_epi32(v));
         return roundtrip - if_then_else(roundtrip > v, 1, 0);
@@ -985,6 +992,12 @@
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_SKX)
     return _mm256_cvtph_ps(h);
 
+#elif defined(JUMPER_IS_VSX) && __has_builtin(__builtin_vsx_xvcvhpsp)
+    #if defined(SK_CPU_LENDIAN)
+        return __builtin_vsx_xvcvhpsp({h[0], 0, h[1], 0, h[2], 0, h[3], 0});
+    #else
+        return __builtin_vsx_xvcvhpsp({0, h[0], 0, h[1], 0, h[2], 0, h[3]});
+    #endif
 #else
     // Remember, a half is 1-5-10 (sign-exponent-mantissa) with 15 exponent bias.
     U32 sem = expand(h),
@@ -1006,6 +1019,13 @@
 #elif defined(JUMPER_IS_HSW) || defined(JUMPER_IS_SKX)
     return _mm256_cvtps_ph(f, _MM_FROUND_CUR_DIRECTION);
 
+#elif defined(JUMPER_IS_VSX) && __has_builtin(__builtin_vsx_xvcvsphp)
+    __vector unsigned short v = __builtin_vsx_xvcvsphp(f);
+    #if defined(SK_CPU_LENDIAN)
+        return U16{v[0], v[2], v[4], v[6]};
+    #else
+        return U16{v[1], v[3], v[5], v[7]};
+    #endif
 #else
     // Remember, a float is 1-8-23 (sign-exponent-mantissa) with 127 exponent bias.
     U32 sem = sk_bit_cast<U32>(f),
@@ -1044,7 +1064,7 @@
     // instead of {b,a} on the stack.  Narrow stages work best for __vectorcall.
     #define ABI __vectorcall
     #define JUMPER_NARROW_STAGES 1
-#elif defined(__x86_64__) || defined(SK_CPU_ARM64)
+#elif defined(__x86_64__) || defined(SK_CPU_ARM64) || defined(SK_CPU_PPC64)
     // These platforms are ideal for wider stages, and their default ABI is ideal.
     #define ABI
     #define JUMPER_NARROW_STAGES 0
@@ -3159,10 +3179,16 @@
     __m256 lo,hi;
     split(x, &lo,&hi);
     return join<F>(_mm256_floor_ps(lo), _mm256_floor_ps(hi));
-#elif defined(JUMPER_IS_SSE41) || defined(JUMPER_IS_AVX)
+#elif defined(JUMPER_IS_SSE41) || \
+  defined(JUMPER_IS_AVX)
+
     __m128 lo,hi;
     split(x, &lo,&hi);
     return join<F>(_mm_floor_ps(lo), _mm_floor_ps(hi));
+#elif defined(JUMPER_IS_VSX)
+    __m128 lo,hi;
+    split(x, &lo,&hi);
+    return join<F>(vec_floor(lo), vec_floor(hi));
 #else
     F roundtrip = cast<F>(cast<I32>(x));
     return roundtrip - if_then_else(roundtrip > x, F(1), F(0));
--- chromium-87.0.4280.67.orig/third_party/skia/src/opts/SkSwizzler_opts.h
+++ chromium-87.0.4280.67/third_party/skia/src/opts/SkSwizzler_opts.h
@@ -12,7 +12,9 @@
 #include "include/private/SkVx.h"
 #include <utility>
 
-#if SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSSE3
+#if defined(SK_PPC64_HAS_SSE_COMPAT)
+    #include <emmintrin.h>
+#elif SK_CPU_SSE_LEVEL >= SK_CPU_SSE_LEVEL_SSSE3
     #include <immintrin.h>
 #elif defined(SK_ARM_HAS_NEON)
     #include <arm_neon.h>
--- chromium-87.0.4280.67.orig/third_party/skia/third_party/skcms/skcms.cc
+++ chromium-87.0.4280.67/third_party/skia/third_party/skcms/skcms.cc
@@ -30,6 +30,8 @@
         #include <avx512fintrin.h>
         #include <avx512dqintrin.h>
     #endif
+#elif defined(__POWER8_VECTOR__)
+    #include <altivec.h>
 #endif
 
 static bool runtime_cpu_detection = true;
--- chromium-87.0.4280.67.orig/third_party/skia/third_party/skcms/src/Transform_inl.h
+++ chromium-87.0.4280.67/third_party/skia/third_party/skcms/src/Transform_inl.h
@@ -44,6 +44,9 @@
 #if !defined(USING_AVX512F)  && N == 16 && defined(__AVX512F__)
     #define  USING_AVX512F
 #endif
+#if !defined(USING_VSX)      && defined(__POWER8_VECTOR__)
+    #define  USING_VSX
+#endif
 
 // Similar to the AVX+ features, we define USING_NEON and USING_NEON_F16C.
 // This is more for organizational clarity... skcms.cc doesn't force these.
@@ -161,6 +164,22 @@
 #elif defined(USING_AVX_F16C)
     typedef int16_t __attribute__((vector_size(16))) I16;
     return __builtin_ia32_vcvtph2ps256((I16)half);
+#elif defined(USING_VSX) && __has_builtin(__builtin_vsx_xvcvhpsp)
+    #if defined(__LITTLE_ENDIAN__)
+        return __builtin_vsx_xvcvhpsp({
+            half[0], 0,
+            half[1], 0,
+            half[2], 0,
+            half[3], 0
+        });
+    #else
+        return __builtin_vsx_xvcvhpsp({
+            0, half[0],
+            0, half[1],
+            0, half[2],
+            0, half[3]
+        });
+    #endif
 #else
     U32 wide = cast<U32>(half);
     // A half is 1-5-10 sign-exponent-mantissa, with 15 exponent bias.
@@ -189,6 +208,13 @@
     return (U16)_mm512_cvtps_ph((__m512 )f, _MM_FROUND_CUR_DIRECTION );
 #elif defined(USING_AVX_F16C)
     return (U16)__builtin_ia32_vcvtps2ph256(f, 0x04/*_MM_FROUND_CUR_DIRECTION*/);
+#elif defined(JUMPER_IS_VSX) && __has_builtin(__builtin_vsx_xvcvsphp)
+    __vector unsigned short v = __builtin_vsx_xvcvsphp(f);
+    #if defined(__LITTLE_ENDIAN__)
+        return U16{v[0], v[2], v[4], v[6]};
+    #else
+        return U16{v[1], v[3], v[5], v[7]};
+    #endif
 #else
     // A float is 1-8-23 sign-exponent-mantissa, with 127 exponent bias.
     U32 sem = bit_pun<U32>(f),
@@ -245,6 +271,8 @@
     return __builtin_ia32_roundps256(x, 0x01/*_MM_FROUND_FLOOR*/);
 #elif defined(__SSE4_1__)
     return _mm_floor_ps(x);
+#elif defined(USING_VSX)
+    return vec_floor(x);
 #else
     // Round trip through integers with a truncating cast.
     F roundtrip = cast<F>(cast<I32>(x));
@@ -1543,5 +1571,8 @@
 #if defined(USING_NEON_FP16)
     #undef  USING_NEON_FP16
 #endif
+#if defined(USING_VSX)
+    #undef  USING_VSX
+#endif
 
 #undef FALLTHROUGH

